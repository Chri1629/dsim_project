{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ambulanze.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUsH/OU8LNaC/3ajmxZ5Ah",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chri1629/dsim_project/blob/main/image/ambulanze.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STPHyzHuuvSc"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from time import time\n",
        "from scipy.io import wavfile as wav\n",
        "import librosa\n",
        "import re\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Classification tools\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "# Advanced audio features\n",
        "import librosa.display\n",
        "from sklearn.preprocessing import scale"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NYIvP6tu6Zk",
        "outputId": "a94b3a96-9964-4a4a-a2c9-1484b0e5de4d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "\n",
        "base_dir = \"gdrive/MyDrive/ambulanze/\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xsnHMyN-zaT"
      },
      "source": [
        "trainAV = pd.read_csv(base_dir + \"train.csv\")\n",
        "testAV = pd.read_csv(base_dir + \"test_vc2kHdQ.csv\")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFGCQmCOAZwu",
        "outputId": "8adefb7d-158f-44a0-f973-6fa3c3235a81"
      },
      "source": [
        "print(len(trainAV) + len(testAV))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Z14HC8VfDhQ5",
        "outputId": "87f6f5e8-a184-461c-a5b2-98b9377eb8b6"
      },
      "source": [
        "testAV.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_names</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1960.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>668.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2082.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>808.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1907.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  image_names\n",
              "0    1960.jpg\n",
              "1     668.jpg\n",
              "2    2082.jpg\n",
              "3     808.jpg\n",
              "4    1907.jpg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYF_kcW0_c0v"
      },
      "source": [
        "def add_class():\n",
        "  labels = []\n",
        "  for f in sorted(os.listdir(base_dir)):\n",
        "    if f.endswith('.jpg'):\n",
        "      if f in trainAV['image_names'].values:\n",
        "        label = trainAV.loc[trainAV['image_names'] == f]['emergency_or_not'].values[0]\n",
        "      else:\n",
        "        label = \"test_image\"\n",
        "      labels.append(label)\n",
        "      #print(labels)\n",
        "    return labels\n"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYCovSN3AoNI",
        "outputId": "c9254162-5098-4414-d1f2-10f25ebbc173"
      },
      "source": [
        "y = add_class()\n",
        "len(y)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIV2LWzqE4Ll"
      },
      "source": [
        "Ora che abbiamo il vettore di label bisogna separare le immagini in due sotto directory in modo che siano facilmente importabili con tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KcT7Dzzu-Sf",
        "outputId": "bcc594a2-ef9b-4df8-df16-36ace2bca2c0"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading https://files.pythonhosted.org/packages/b8/5f/3c2b2f7ea5e047c8cdc3bb00ae582c5438fcdbbedcc23b3cc1c2c7aae642/split_folders-0.4.3-py3-none-any.whl\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75Nl5pKGvG2q",
        "outputId": "c2989a59-8d03-40c4-9265-66eb54da1a16"
      },
      "source": [
        "import splitfolders\n",
        "splitfolders.ratio(\"gdrive/MyDrive/ambulanze\", output=\"gdrive/MyDrive/ambulanze_model\", ratio=(0.6, 0.3, 0.1))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying files: 0 files [00:00, ? files/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWD379f3vq86"
      },
      "source": [
        "# Modelli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MgLhM79vLkD"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import xception"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "sND0O9AXvtk7",
        "outputId": "2006d3b9-ad53-4321-9318-c4461e15827a"
      },
      "source": [
        "train_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function = xception.preprocess_input)\n",
        "\n",
        "train_generator = train_processing.flow_from_directory(\"gdrive/MyDrive/ambulanze_model/train\",\n",
        "                                    target_size = (224, 224),\n",
        "                                    color_mode = \"rgb\",\n",
        "                                    batch_size = 32,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    shuffle = True,\n",
        "                                    seed = 1)\n",
        "\n",
        "x_train, y_train = next(train_generator)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e248d948387d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                                     \u001b[0mclass_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                     seed = 1)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gdrive/MyDrive/ambulanze_model/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgztX5gfvthp"
      },
      "source": [
        "validation_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= xception.preprocess_input)\n",
        "\n",
        "validation_generator = validation_processing.flow_from_directory(\"gdrive/MyDrive/ambulanze_model/val\",\n",
        "                                    target_size = (224, 224),\n",
        "                                    color_mode = \"rgb\",\n",
        "                                    batch_size = 32,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    shuffle = True,\n",
        "                                    seed = 1)\n",
        "x_validation, y_validation = next(validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXY3AVSMvtea"
      },
      "source": [
        "test_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= xception.preprocess_input)\n",
        "\n",
        "test_generator = test_processing.flow_from_directory(\"gdrive/MyDrive/ambulanze_model/test\",\n",
        "                                    target_size = (224, 224),\n",
        "                                    color_mode = \"rgb\",\n",
        "                                    batch_size = 32,\n",
        "                                    class_mode = \"categorical\",\n",
        "                                    shuffle = False,\n",
        "                                    seed = 1)\n",
        "x_test, y_test = next(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUv3pXxQvtZe"
      },
      "source": [
        "from tensorflow.keras.applications import xception\n",
        "base_net = xception.Xception(input_shape = (224,224,3),\n",
        "                        weights = 'imagenet',\n",
        "                        include_top = False,\n",
        "                        pooling = 'avg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZYINE7Cv6HE"
      },
      "source": [
        "for layer in base_net.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHJYWS6v6ET"
      },
      "source": [
        "x = base_net.output\n",
        "\n",
        "x = keras.layers.Dense(64, activation = \"relu\") (x)\n",
        "pred = keras.layers.Dense(2, activation = 'sigmoid') (x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykEZ5WzRv6BJ"
      },
      "source": [
        "net1 = keras.Model(inputs = base_net.input, outputs = pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVNq0u5Ov58u"
      },
      "source": [
        "net1.compile(loss = keras.losses.categorical_crossentropy,\n",
        "           optimizer = keras.optimizers.RMSprop(),\n",
        "           metrics = ['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZ8nqDkv_gO"
      },
      "source": [
        "hist1 = net1.fit(train_generator,\n",
        "       epochs = 5,\n",
        "       validation_data = validation_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bg4o75jv_c9"
      },
      "source": [
        "def acc_loss(history):\n",
        "    plt.figure(figsize=(14,5))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'], label = \"Train loss\", color = \"red\")\n",
        "    plt.plot(history.history['val_loss'], label=\"Validation loss\", color = \"skyblue\")\n",
        "    plt.legend(loc='upper right', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Loss', size = 15) \n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['accuracy'], label = \"Train accuracy\", color = \"red\")\n",
        "    plt.plot(history.history['val_accuracy'], label=\"Validation accuracy\", color = \"skyblue\")\n",
        "    plt.legend(loc='upper right', fontsize = 12)\n",
        "    plt.xticks(fontsize = 12)\n",
        "    plt.yticks(fontsize = 12)\n",
        "    plt.xlabel('Epochs', size = 15)\n",
        "    plt.ylabel('Accuracy', size = 15) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tg_01kvxv_Yh"
      },
      "source": [
        "acc_loss(hist1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaoTvQkhwFWF"
      },
      "source": [
        "acc1 = net1.evaluate(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_woVxxS3wFSj"
      },
      "source": [
        "pred_1 = net1.predict(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTGwtdGewFOk"
      },
      "source": [
        "pred_1 = np.argmax(pred_1, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU9o33VXwPRD"
      },
      "source": [
        "print(classification_report(test_generator.classes, pred_1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qk2-r_nPwPNE"
      },
      "source": [
        "cm = confusion_matrix(test_generator.classes, pred_1)\n",
        "\n",
        "fig = plt.figure(figsize = (6,6))\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(cm, annot=True, annot_kws={\"size\": 16},\n",
        "           linewidths=.1, cmap=\"YlGnBu\")\n",
        "plt.xlabel(\"True Class\", size = 15)\n",
        "plt.ylabel(\"Predicted Class\", size = 15)\n",
        "plt.xticks(size = 12)\n",
        "plt.yticks(size = 12)\n",
        "ax.yaxis.set_ticklabels(['Letto', 'Improvvisato']) \n",
        "ax.xaxis.set_ticklabels(['Letto', 'Improvvisato']) \n",
        "#ax.set_yticklabels(['Letto', 'Improvvisato'], rotation=90, ha='right', minor=False)\n",
        "\n",
        "plt.title(\"Confusion matrix\", size = 20)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}