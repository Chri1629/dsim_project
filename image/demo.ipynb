{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Progetto di Digital Signal & Image Management**\n",
    "\n",
    "## **Parte 2 - Image Classification - DEMO**\n",
    "\n",
    "*2020/2021*\n",
    "\n",
    "Peracchi Marco 800578\n",
    "\n",
    "Uccheddu Christian 800428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from scipy.io import wavfile as wav\n",
    "import IPython.display as ipd\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "import cv2 as cv\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import mobilenet\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.models.load_model('modello_immagini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1091212e-17 1.3969539e-36]]\n",
      "[[0.7941828 0.       ]]\n",
      "[[1.3692086e-13 0.0000000e+00]]\n",
      "[[1.7420531e-09 0.0000000e+00]]\n",
      "[[2.9497946e-07 0.0000000e+00]]\n",
      "[[6.940721e-13 0.000000e+00]]\n",
      "[[6.1297256e-12 0.0000000e+00]]\n",
      "[[1.241092e-08 0.000000e+00]]\n",
      "[[2.4744253e-05 0.0000000e+00]]\n",
      "[[0.0294305 0.       ]]\n",
      "[[1.8946682e-19 3.2437451e-35]]\n",
      "[[2.1413255e-15 0.0000000e+00]]\n",
      "[[1.973253e-08 0.000000e+00]]\n",
      "[[5.884169e-13 0.000000e+00]]\n",
      "[[3.961338e-10 0.000000e+00]]\n",
      "[[6.4042645e-15 1.9700339e-38]]\n",
      "[[9.629221e-07 0.000000e+00]]\n",
      "[[6.1243236e-13 0.0000000e+00]]\n",
      "[[2.0496096e-19 1.7549074e-30]]\n",
      "[[4.8746742e-22 4.5956486e-27]]\n",
      "[[1.4734766e-19 0.0000000e+00]]\n",
      "[[1.2071352e-18 0.0000000e+00]]\n",
      "[[5.082049e-20 0.000000e+00]]\n",
      "[[2.3665247e-17 0.0000000e+00]]\n",
      "[[5.0394496e-25 0.0000000e+00]]\n",
      "[[3.6300950e-19 1.0295857e-36]]\n",
      "[[1.2836787e-21 1.5726807e-30]]\n",
      "[[1.0586906e-24 1.6132788e-28]]\n",
      "[[1.2078596e-16 1.7915206e-38]]\n",
      "[[2.1964170e-22 1.1392262e-28]]\n",
      "[[5.2542955e-23 3.8466595e-32]]\n",
      "[[3.3652860e-29 2.6142656e-30]]\n",
      "[[4.6214257e-25 2.6583215e-31]]\n",
      "[[3.0147882e-25 2.1061265e-37]]\n",
      "[[4.097490e-28 4.166618e-38]]\n",
      "[[4.3580502e-19 5.2782014e-38]]\n",
      "[[1.1013423e-25 9.4427682e-33]]\n",
      "[[4.6131826e-25 2.1334155e-31]]\n",
      "[[1.764936e-24 7.241852e-31]]\n",
      "[[2.1931147e-14 1.8722641e-36]]\n",
      "[[9.1699116e-14 1.4189914e-35]]\n",
      "[[1.3404081e-12 1.6588843e-38]]\n",
      "[[2.0069876e-25 1.9702849e-35]]\n",
      "[[3.7399954e-22 0.0000000e+00]]\n",
      "[[9.4844406e-23 1.6383497e-32]]\n",
      "[[1.2916709e-28 9.0366691e-29]]\n",
      "[[4.0769318e-25 1.3572480e-28]]\n",
      "[[1.2148632e-19 1.5893666e-25]]\n",
      "[[9.5923190e-24 6.2723184e-25]]\n",
      "[[1.5444443e-18 2.1488203e-23]]\n",
      "[[1.3313776e-20 1.5259087e-19]]\n",
      "[[1.6562989e-22 5.1643529e-17]]\n",
      "[[4.9637533e-21 2.0921028e-13]]\n",
      "[[1.0997429e-32 3.2014202e-02]]\n",
      "[[1.8515390e-36 1.6586822e-06]]\n",
      "[[3.0079602e-28 1.0863668e-17]]\n",
      "[[7.9098600e-25 3.4178687e-19]]\n",
      "[[1.6720437e-28 4.6488912e-15]]\n",
      "[[6.434525e-32 8.799111e-14]]\n",
      "[[2.502700e-22 5.070633e-24]]\n",
      "[[2.3547274e-25 4.7758400e-19]]\n",
      "[[8.7168731e-22 1.1307775e-23]]\n",
      "[[1.1599321e-22 5.6964953e-26]]\n",
      "[[6.5229954e-19 1.0901801e-28]]\n",
      "[[7.2022882e-24 3.6099007e-22]]\n",
      "[[6.3213295e-22 5.6915734e-23]]\n",
      "[[1.2410079e-14 5.8796520e-19]]\n",
      "[[1.2103423e-14 3.7123506e-21]]\n",
      "[[1.04652535e-29 4.14193119e-06]]\n",
      "[[1.0200819e-21 2.1110206e-11]]\n",
      "[[1.4954094e-17 1.2747370e-09]]\n",
      "[[3.6193880e-14 1.8907271e-14]]\n",
      "[[2.9457837e-24 6.2637140e-09]]\n",
      "[[3.4458810e-21 3.3233114e-08]]\n",
      "[[5.5390825e-10 7.9096459e-11]]\n",
      "[[1.19265005e-05 1.81524073e-15]]\n",
      "[[3.8530839e-06 1.1417741e-12]]\n",
      "[[2.681907e-08 8.663342e-13]]\n",
      "[[2.2970974e-06 1.5948341e-16]]\n",
      "[[9.030852e-07 7.009406e-10]]\n",
      "[[1.3430396e-07 2.6359172e-14]]\n",
      "[[2.6479431e-12 2.2389693e-10]]\n",
      "[[5.1131543e-12 1.1973109e-12]]\n",
      "[[6.0902800e-15 1.7976353e-14]]\n",
      "[[1.0831250e-09 1.3604552e-15]]\n",
      "[[3.607541e-10 9.345163e-16]]\n",
      "[[3.310486e-09 4.454255e-27]]\n",
      "[[2.0960817e-05 5.1446703e-32]]\n",
      "[[3.2944547e-07 9.3794093e-32]]\n",
      "[[4.4388389e-11 2.2832768e-29]]\n",
      "[[5.9500422e-07 1.6913834e-38]]\n",
      "[[1.6085902e-04 1.0121167e-36]]\n",
      "[[3.6061268e-05 2.7440935e-34]]\n",
      "[[2.7431131e-09 6.4388064e-22]]\n",
      "[[3.5349240e-05 3.3042922e-35]]\n",
      "[[2.3957167e-02 1.0867979e-32]]\n",
      "[[2.8702867e-13 3.2212682e-26]]\n",
      "[[4.3269749e-11 2.0601763e-19]]\n",
      "[[3.6083597e-10 2.4510735e-23]]\n",
      "[[5.0574046e-15 6.3490584e-19]]\n",
      "[[9.1960356e-03 1.7880795e-38]]\n",
      "[[3.1572871e-08 5.1163053e-27]]\n",
      "[[4.7366714e-04 2.0258804e-24]]\n",
      "[[9.0562993e-01 2.1678883e-31]]\n",
      "[[4.2154258e-01 3.9570780e-33]]\n",
      "[[9.559054e-01 6.437935e-33]]\n",
      "[[4.880599e-01 9.025581e-28]]\n",
      "[[9.9996579e-01 1.8300335e-33]]\n",
      "[[9.998740e-01 6.514931e-36]]\n",
      "[[1.6010604e-20 3.5945132e-13]]\n",
      "[[5.0015666e-18 3.4376087e-14]]\n",
      "[[3.8529641e-11 4.2515003e-25]]\n",
      "[[3.8791547e-23 1.2594387e-17]]\n",
      "[[8.7292119e-16 2.3386135e-18]]\n",
      "[[4.1235763e-31 3.8022025e-12]]\n",
      "[[0.         0.01256233]]\n",
      "[[2.59449006e-34 1.14276155e-07]]\n",
      "[[0. 1.]]\n",
      "[[1.3571168e-38 8.6331880e-01]]\n",
      "[[1.6671252e-30 8.9234066e-01]]\n",
      "[[1.7804043e-28 7.4008964e-02]]\n",
      "[[4.5434523e-30 1.2964663e-10]]\n",
      "[[1.0541477e-26 1.2539570e-03]]\n",
      "[[4.8634977e-35 9.8542681e-05]]\n",
      "[[6.4312366e-17 4.5397147e-13]]\n",
      "[[7.3381519e-09 1.0522086e-16]]\n",
      "[[3.0825706e-07 1.1759488e-22]]\n",
      "[[3.8744359e-16 1.7162265e-09]]\n",
      "[[4.3932085e-09 3.4992528e-20]]\n",
      "[[1.9394636e-06 6.9111916e-18]]\n",
      "[[3.6448625e-17 3.6501945e-08]]\n",
      "[[4.5110926e-13 3.9909482e-16]]\n",
      "[[1.07705004e-16 4.52525592e-06]]\n",
      "[[1.9816246e-13 1.3376835e-11]]\n",
      "[[6.0741779e-15 1.2885813e-19]]\n",
      "[[7.1901959e-06 1.2166638e-17]]\n",
      "[[3.8441397e-07 2.6430277e-20]]\n",
      "[[3.5833532e-04 1.4743117e-15]]\n",
      "[[2.7805501e-07 3.5958772e-17]]\n",
      "[[2.9365634e-30 1.0000000e+00]]\n",
      "[[2.5062634e-06 3.4534039e-16]]\n",
      "[[1.2587934e-27 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "cap = cv.VideoCapture(\"test_3.avi\")\n",
    "start_time = time()\n",
    "while (time() - start_time) < 50:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    #Convert the captured frame into RGB\n",
    "    im = Image.fromarray(frame, 'RGB')\n",
    "\n",
    "    #Resizing into 128x128 because we trained the model with this image size.\n",
    "    im = im.resize((224,224))\n",
    "    img_array = np.array(im)\n",
    "\n",
    "    #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "    #So changing dimension 128x128x3 into 1x128x128x3 \n",
    "    \n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    #Calling the predict method on model to predict 'me' on the image\n",
    "    #prediction = int(model_1.predict(img_array)[0][0])\n",
    "    prediction = model_1.predict(img_array)\n",
    "    \n",
    "    result = np.argmax(prediction, axis = 1)\n",
    "    \n",
    "    if result == 0:\n",
    "        label = \"No\"\n",
    "    else:\n",
    "        label = \"Yes\"\n",
    "    \n",
    "\n",
    "    #if prediction is 0, which means I am missing on the image, then show the frame in gray color.\n",
    "    \n",
    "    text = \"Emergency: {}{}\".format(label, prediction)\n",
    "    cv.putText(frame, text, (35, 50), cv.FONT_HERSHEY_SIMPLEX,\n",
    "        1.25, (0, 255, 0), 5)\n",
    "\n",
    "    cv.imshow(\"Capturing\", frame)\n",
    "    key=cv.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<VideoCapture 0000027ACE94ADD0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "single_processing = keras.preprocessing.image.ImageDataGenerator(preprocessing_function= mobilenet.preprocess_input)\n",
    "\n",
    "single_generator = single_processing.flow_from_directory(\"single\",\n",
    "                                    target_size = (224, 224),\n",
    "                                    color_mode = \"rgb\",\n",
    "                                    batch_size = 1,\n",
    "                                    class_mode = \"categorical\",\n",
    "                                    shuffle = False,\n",
    "                                    seed = 1)\n",
    "test,label_test = next(single_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model_1 = tf.keras.models.load_model('modello_audio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x272ca54d700>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = model_1.predict(test)\n",
    "test_features = test_features.reshape(test_features.shape[0],\n",
    "                                      test_features.shape[1]*test_features.shape[2]*test_features.shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-5573d62d8811>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlr_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"lbfgs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpenalty\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'l2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlr_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_train' is not defined"
     ]
    }
   ],
   "source": [
    "lr_1 = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\", max_iter=30, penalty ='l2', verbose = 1)\n",
    "lr_1.fit(test_features, tf.argmax(y_train, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a6434ecb694c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_finali\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m         \"\"\"\n\u001b[1;32m--> 309\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    280\u001b[0m             \u001b[1;32mclass\u001b[0m \u001b[0mwould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m         \"\"\"\n\u001b[1;32m--> 282\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\machinelearning\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1040\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1041\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1042\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This LogisticRegression instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "pred_finali = lr_1.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_finali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in pred_finali]\n",
    "\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
